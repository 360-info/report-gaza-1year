---
title: Casualties between Palestine, Israel and Lebanon
format:
  360-analysis-html: default
author: James Goldie
date: last-modified
code-fold: true
---

```{r}
#| label: setup
library(tidyverse)
library(rvest)
library(httr2)
library(here)
```

# Gaza

```{r}
#| label: load-data
here("data", "raw", "gaza-casualties-daily.csv") |>
  read_csv() ->
gaza_casualties
```

Are there multiple reports on any given day?

```{r}
#| label: check-date-dupes
gaza_casualties |>
  count(report_date) |>
  filter(n > 1)
```

Good! Let's compare the cumulative count to the daily casualty reports:

```{r}
#| label: compare-estimates
gaza_casualties |>
  select(report_date, killed, killed_cum) |>
  mutate(
    killed_filled = replace_na(killed, 0),
    killed_cum_manual_upper = cumsum(killed_filled),
    killed_cum_manual_lower = killed_cum_manual_upper - killed_filled) |>
  ggplot() +
    aes(x = report_date) +
    geom_linerange(
      aes(ymin = killed_cum_manual_lower, ymax = killed_cum_manual_upper),
      colour = "slategrey") +
    geom_line(
      aes(y = killed_cum), colour = "orangered", linetype = "dashed") +
    annotate_360_light(
      x = as.Date("2023-11-01"), y = 39000, hjust = "inward",
      label = paste(
        "The Gaza Ministry of Health estimates that",
        "**over 41 500 Palestinians** have died",
        "as of September 29...",
        sep = "<br>"
      )
    ) +
    annotate_360_dark(
      x = as.Date("2023-11-18"), y = 6300, hjust = "inward",
      label = paste(
        "... but not everyone is completely accounted for.",
        "Identifying bodies, especially as hospitals are bombed",
        "and their data is lost, makes counting the dead challenging.",
        sep = "<br>"
      )
    ) +
    scale_y_continuous(
      labels = scales::label_number(scale_cut = scales::cut_short_scale())) +
    theme_360() +
    labs(
      x = NULL, y = NULL,
      title = toupper("Gaza casualties: Palestine"),
      caption = paste(
        "**CHART:** James Goldie, 360info",
        "**DATA: Tech for Palestine <techforpalestine.org>",
        sep = "<br>"
      )) ->
plot_gaza_casualty_estimate

dir.create(here("out"), showWarnings = FALSE, recursive = TRUE)
plot_gaza_casualty_estimate |>
  save_360plot(here("out", "gaza-casualty-est.png"))
```

## Demographics

Now let's break down demographics:


```{r}
#| label: demographics
gaza_casualties |>
  mutate(ext_killed_adults_cum = ext_killed_cum - ext_killed_children_cum) |>
  select(
    report_date,
    Children = ext_killed_children_cum,
    Adults = ext_killed_adults_cum) |>
    mutate(pct_kids = Children / (Adults + Children)) |>
  plot(pct_kids ~ report_date, data = _)

  write_csv(here("data", "gaza-killed-adults-children.csv")) |>
  pivot_longer(-report_date) |>
  ggplot() +
    aes(x = report_date, y = value, fill = name, colour = name) +
    geom_area() +
    scale_y_continuous(
      labels = scales::label_number(scale_cut = scales::cut_short_scale()),
      sec.axis = dup_axis()) +
    guides(colour = "none", fill = "none") +
    theme_360() +
    theme(
      panel.grid.major.x = element_blank(),
      panel.grid.minor.x = element_blank(),
      panel.grid.minor.y = element_blank(),
    ) +
    annotate("text",
      x = as.Date("2024-07-01"), y = 25000, hjust = "inward",
      label = "Adults",
      colour = "firebrick", family = "Body 360info", fontface = "bold", size = 8
    ) +
    annotate("text",
      x = as.Date("2024-07-01"), y = 7000, hjust = "inward",
      label = "Children",
      colour = "navy", family = "Body 360info", fontface = "bold", size = 8
    ) +
    labs(
      x = NULL, y = NULL,
      title = toupper("Gaza casualties: Palestine"),
      caption = paste(
        "**CHART:** James Goldie, 360info",
        "**DATA: Tech for Palestine <techforpalestine.org>",
        sep = "<br>"
      ))
```

# Israeli casualties

OCHA Humanitarian Situation Updates (or "Flash Updates") contain estimates of Israeli casualties. I might be able to scrape the text to speed up getting the estimates for each day.

The URLs seem to be pretty stable, but Wednesday updates are for West Bank, while Monday and Friday updates are for Gaza Strip. I'm just going to try them all and drop the ones that 404.

Before May 31 2024, they have a different URL scheme but the same page structure.

The update's article text is in `#section-content .content`, while the publication date is in `#section-content .content .date time`.

```{r}
#| label: scrape-fn
scrape_ocha_update_text <- function(url) {
  url |>
    read_html() |>
    html_elements("#section-content .content") ->
  content

  content |>
    html_elements(".date time") |>
    html_text() ->
  pub_date

  content |>
    html_text() ->
  article

  return(list(pub_date = pub_date, article = article))
}

safe_slow_ocha_scrape <- safely(slowly(scrape_ocha_update_text, ))
```

```{r}
#| label: scrape
paste0(
  "https://www.ochaopt.org/content/humanitarian-situation-update-",
  173:223, 
  "-gaza-strip") |>
  tibble(url = _) |>
  mutate(res = map(url, safe_slow_ocha_scrape)) ->
flash_updates_since_may

paste0(
  "https://www.ochaopt.org/content/",
  "hostilities-gaza-strip-and-israel-flash-update-",
  1:172) |>
  tibble(url = _) |>
  mutate(res = map(url, safe_slow_ocha_scrape)) ->
flash_updates_upto_may

flash_updates_since_may |>
  bind_rows(flash_updates_upto_may) ->
flash_updates
```
```{r}
#| label: extract-updates

# drop the missing updates; extract dates and article text
flash_updates |>
  mutate(has_update = map_lgl(res, ~ !is.null(.x$result))) |>
  filter(has_update) |>
  mutate(
    pub_date = dmy(map_chr(res, ~ .x$result$pub_date)),
    article = map_chr(res, ~ .x$result$article)) ->
flash_update_stories
  
# write each story out to disk
dir.create(here("data", "raw", "flash-updates-gaza"), showWarnings = FALSE)
walk2(flash_update_stories$pub_date, flash_update_stories$article,
  ~ writeLines(.y,  here("data", "raw", "flash-updates-gaza",
    paste0(.x, ".txt"))))
```

If we had more time, I'd consider using an LLM to automate the extraction of the relevant statistics from this. But for now, let's just go through the updates manually and pull them out. We'll put them into `data/israel-killed.csv`.

Let's single out the par that contains the word 'Israelis', since usually that's where casualties are spoken about.

```{r}
#| label: extract-casualties

extract_casualty_par <- function(article) {
  article |>
    str_split("[\\n\\t]+") |> pluck(1) |>
    str_replace_all("\\s+", " ") ->
  tidied_article

  tidied_article |>
    str_detect(coll("Israelis")) ->
  to_keep
  
  # return the par (or full story if no match)
  if (length(tidied_article[to_keep]) == 0) {
    return(article)
  } else {
    return(paste(tidied_article[to_keep], collapse = "\n\n"))
  }
}

flash_update_stories |>
  mutate(par = map_chr(article, extract_casualty_par)) |>
  filter(!is.na(par)) ->
flash_updates_extracted

# write each story out to disk
dir.create(here("data", "raw", "flash-updates-extracted"), showWarnings = FALSE)
walk2(flash_updates_extracted$pub_date, flash_updates_extracted$par,
  ~ writeLines(.y,  here("data", "raw", "flash-updates-extracted",
    paste0(.x, ".txt"))))
```

I've manually pulled the number of soldiers killed in each day's Flash Update out to `data/raw/israel-killed.csv`.

We'll add to this victims of the October 7 attacks, as reported by [Action on Armed Violence](https://aoav.org.uk/2023/an-analysis-of-the-7th-of-october-2023-casualties-in-israel-as-a-result-of-the-hamas-attack) in December 2023.

```{r}
#| label: add-oct7
here("data", "raw", "israel-killed.csv") |>
  read_csv() |>
  mutate(
    killed_all = killed_soldiers_gaza + 1269,
    killed_children = 24,
    killed_adults = killed_all - killed_children) ->
israel_casualties
```

Let's combine Israeli and Palestinian casualties:

```{r}
#| label: join-countries
gaza_casualties |>
  mutate(ext_killed_adults_cum = ext_killed_cum - ext_killed_children_cum) |>
  select(
    date = report_date,
    `Palestine children` = ext_killed_children_cum,
    `Palestine adults` = ext_killed_adults_cum) ->
gaza_fordw

israel_casualties |>
  select(date,
    `Israel children` = killed_children,
    `Israel adults` = killed_adults) ->
israel_fordw

# write out for datawrapper, filling missing values in the israeli reports
full_join(gaza_fordw, israel_fordw, join_by(date)) |>
  fill(starts_with("Israel")) ->
gaza_israel_casualties
```

# Lebanon

Let's try to use the ACLED API to get an idea of casualties. It returns JSON by default, but you can return XML or CSVs by simply appending the file extension to the path (before the query string parameter).

```{r}
#| label: acled-credentials
api_key   <- Sys.getenv("ACLED_API_KEY")
api_email <- Sys.getenv("ACLED_API_EMAIL")
api_root  <- "https://api.acleddata.com/"
```

```{r}
#| label: get-data

req_start <- as.Date("2023-10-06")
req_end   <- Sys.Date()

# no more pages needed if < 5000 rows returned
request_complete <- function(resp) {
  n_rows <-
    resp |>
    resp_body_string() |>
    read_csv() |>
    nrow()
  n_rows < 5000
}

# run a series of requests, stopping when we get one
# with < 5000 rows of data
request(api_root) |>
  req_url_path_append("acled") |>
  req_url_path_append("read.csv") |>
  req_url_query(
    key = api_key,
    email = api_email,
    country = "Lebanon") |>
  req_throttle(1 / 3) |>
  req_perform_iterative(next_req =
    iterate_with_offset("page",
      resp_complete = request_complete)) ->
events_list

# now extract all the responses and g
events_list |>
  map(~ read_csv(resp_body_string(.x))) |>
  bind_rows() ->
all_events
```

Let's make sure we understand the shape of the data we're looking at. I want to focus on events in which Israel was one of the two actors listed:

```{r}
#| label: events-vis
all_events |>
  filter(str_detect(actor1, "Israel") | str_detect(actor2, "Israel")) ->
lebanon_israel_events

# total fatalities
lebanon_israel_events |>
  pull(fatalities) |>
  sum(na.rmn = TRUE)
```

1224 fatalities squares well with media reports. What kind of events are they distributed across?

```{r}
# actors
lebanon_israel_events |>
  group_by(actor1, actor2) |>
  summarise(
    n_events = n(),
    sum_fatalities = sum(fatalities, na.rm = TRUE)) |>
  arrange(desc(sum_fatalities)) |>
  print(n = Inf)

# event distribution
lebanon_israel_events |>
  group_by(disorder_type, event_type, actor1, actor2) |>
  summarise(
    n_events = n(),
    sum_fatalities = sum(fatalities, na.rm = TRUE)) |>
    arrange(desc(sum_fatalities)) |>
    View()
```

Looks like 

The ACLED dataset does not assign any judgement to `actor1` and `actor2` respectively, and fatalities are not grouped by nationality or group, so it's difficult to know whether these are all Lebanese casualties.

Let's look into the notes a bit more to see if we can work this out better. I see the phrase "Israeli warplanes carried out" in many events — how many events and fatalities is that?

```{r}
#| label: israeli-warplanes
lebanon_israel_events |>
  select(event_date, disorder_type, event_type, actor1, actor2, fatalities, notes) |>
  filter(
    str_detect(notes, "Israeli F-35 and F-15 fighter jets carried out") |
    str_detect(notes, "Israeli warplanes carried out") |
    str_detect(notes, "Israeli warplanes, including fighter jets, carried out") |
    str_detect(notes, "Israeli airplanes carried out") | 
    str_detect(notes, "Israeli jets carried out") |
    str_detect(notes, "Israeli drones carried out") |
    str_detect(notes, "Israeli drone carried out") |
    str_detect(notes, "Israeli drone targeted") |
    str_detect(notes, "Israeli drone struck") |
    str_detect(notes, "Israeli drone directly struck") |
    str_detect(notes, "Israeli drone fired rockets") |
    str_detect(notes, "Israeli drone dropped") |
    str_detect(notes, "Israeli fighter jets struck") |
    str_detect(notes, "Israeli military fired artillery") |
    str_detect(notes, "Israeli military fired mortar") |
    str_detect(notes, "Israeli military forces shelled") |
    str_detect(notes, "Israeli drone fired rockets") |
    str_detect(notes, "Israeli military forces bombarded") |
    str_detect(notes, "Israeli military launched a suicide drone")
    ) ->
israeli_air_events

n_lebanon_israel_events <- lebanon_israel_events |> nrow()
n_lebanon_israel_fatalities <-
  lebanon_israel_events |> pull(fatalities) |> sum(na.rm = TRUE)

# num events/fatalities from israeli warplanes
n_israeli_air_events <-
  israeli_air_events |> nrow()
n_israeli_warplane_fatalities <- 
  israeli_air_events |> pull(fatalities) |> sum(na.rm = TRUE)
```

`{r} scales::percent(n_israeli_air_events / n_lebanon_israel_events)` of events and about `{r} scales::percent(n_israeli_warplane_fatalities / n_lebanon_israel_fatalities)` of casualties are linked to the phrases of the form, "Israeli [planes/warplanes/jets/drones] carried out/struck/fired/dropped/targeted" in the Notes.

Let's work out daily fatalities to combine with the Gaza and Israel counts. (We'll need a note about not being attribute all the fatalities to Lebanon in the final text.)

```{r}
#| label: daily-lebanon
lebanon_israel_events |>
  group_by(event_date) |>
  summarise(fatalities = sum(fatalities, na.rm = TRUE)) |>
  # cut to the first fatality
  filter(event_date >= as.Date("2023-10-07")) |>
  # work out cumulative
  mutate(fatalities_cum = cumsum(fatalities)) |>
  write_csv(here("data", "lebanon-killed.csv")) ->
lebanon_casualties

# merge with gaza and israel
lebanon_casualties |>
  select(date = event_date, `Killed in Lebanon` = fatalities_cum) |>
  full_join(gaza_israel_casualties, join_by(date)) |>
  arrange(date) |>
  write_csv(here("data", "daily-killed-cumulative.csv"), na = "") ->
all_casualties
```

# Extrapolate adult/child ratio for Gaza

Michael Spagat, our author on this, is confused by the difference in adults and children killed in the cumulative daily counts from TFP and the named list. He's suggested we take the total figures there but extrapolate the adult/child fraction from their named lists of cases instead.

TFP doesn't seem to offer _all_ of MoH's named lists — only the current one — but let's start with that.

```{r}
cum_pal_latest_children <-
  gaza_israel_casualties |> tail(1) |> pull("Palestine children")
cum_pal_latest_adults <-
  gaza_israel_casualties |> tail(1) |> pull("Palestine adults")
```

The cumulative figures we had from TFP had `{r} cum_pal_latest_children` children (`{r} scales::percent(cum_pal_latest_children / (cum_pal_latest_adults + cum_pal_latest_children))`) and `{r} cum_pal_latest_adults` (`{r} scales::percent(cum_pal_latest_adults / (cum_pal_latest_adults + cum_pal_latest_children))`)

It also doesn't classify casualties as adults or children. Let's see what the age breakdown is.

```{r}
#| label: download-named-list
named_list_path <- here("data", "raw", "tfp-named-killed.csv")
download.file(
  "https://data.techforpalestine.org/api/v2/killed-in-gaza.csv",
  named_list_path)

named_list <- read_csv(named_list_path)

# total
nrow(named_list)
  
# current ratios
named_list |>
  mutate(age_group = cut(age, c(0, 5, 10, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 120))) |>
  count(age_group) |>
  mutate(
    n_lte = cumsum(n),
    pct_lte = n_lte / n_lte[n()]) ->
named_agegroups
```

Here, 40.6% of casualties are under 21 under 22 or younger; just 31% are under 18. (Much lower than the 40% or so of children in the TFP data.)

Unfortunately we can't verify whether this data has changed over time, as the TFP data only includes the latest list, not previous ones (and it doesn't have the date of death).

But for now, we can apply this percentage to the TFP total killed and work out the upper and lower bounds for the number of children based on the respective percentages.


```{r}
#| label: rescale-figures
pct_children_est <-
  named_agegroups |> filter(age_group == "(16,17]") |> pull("pct_lte")

all_casualties |>
  janitor::clean_names() |>
  rename(
    palestine_children_tfp = palestine_children,
    palestine_adults_tfp = palestine_adults
    ) |>
  mutate(
    # recalculate the split with this new percentage
    palestine_total = palestine_children_tfp + palestine_adults_tfp,
    palestine_children_adj = palestine_total * pct_children_est,
    palestine_unknown = palestine_children_tfp - palestine_children_adj,
    palestine_adults_adj =
      palestine_total - palestine_children_adj - palestine_unknown) |>
  write_csv(here("data", "daily-killed-cumulative.csv"), na = "") ->
all_casualties_rescaled
```

Now we can show both estimates and and discuss some of the uncertainty involved.
